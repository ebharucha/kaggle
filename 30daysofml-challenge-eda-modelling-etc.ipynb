{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Overview\n\nFor this competition, you will be predicting a continuous target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat9 are categorical, and the feature columns cont0 - cont13 are continuous.\n\n@ebharucha - Aug 2021","metadata":{}},{"cell_type":"markdown","source":"### Import dependencies","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, StackingRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import RootMeanSquaredError\nfrom keras.wrappers.scikit_learn import KerasRegressor\n\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport string\nimport pickle\nfrom collections import Counter\n\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ngc.collect()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-01T00:14:12.663616Z","iopub.execute_input":"2021-09-01T00:14:12.663993Z","iopub.status.idle":"2021-09-01T00:14:12.921879Z","shell.execute_reply.started":"2021-09-01T00:14:12.663961Z","shell.execute_reply":"2021-09-01T00:14:12.920917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/30-days-of-ml/train.csv')\ntest_df = pd.read_csv('/kaggle/input/30-days-of-ml/test.csv')\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\n# All categorical columns\nobject_cols = [col for col in train_df.columns if train_df[col].dtype == \"object\"]\n\n# All numerical columns\ncont_cols = [col for col in train_df.columns if train_df[col].dtype != \"object\"]\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:18:50.750117Z","iopub.execute_input":"2021-09-01T00:18:50.750558Z","iopub.status.idle":"2021-09-01T00:18:52.863749Z","shell.execute_reply.started":"2021-09-01T00:18:50.750515Z","shell.execute_reply":"2021-09-01T00:18:52.862888Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont5     cont6  \\\n0   1    B    B    B    C    B    B    A    E    C  ...  0.400361  0.160266   \n1   2    B    B    A    A    B    D    A    F    A  ...  0.533087  0.558922   \n2   3    A    A    A    C    B    D    A    D    A  ...  0.650609  0.375348   \n3   4    B    B    A    C    B    D    A    E    C  ...  0.668980  0.239061   \n4   6    A    A    A    C    B    D    A    E    A  ...  0.686964  0.420667   \n\n      cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n0  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n1  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n2  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n3  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n4  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n\n     target  \n0  8.113634  \n1  8.481233  \n2  8.364351  \n3  8.049253  \n4  7.972260  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.400361</td>\n      <td>0.160266</td>\n      <td>0.310921</td>\n      <td>0.389470</td>\n      <td>0.267559</td>\n      <td>0.237281</td>\n      <td>0.377873</td>\n      <td>0.322401</td>\n      <td>0.869850</td>\n      <td>8.113634</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.533087</td>\n      <td>0.558922</td>\n      <td>0.516294</td>\n      <td>0.594928</td>\n      <td>0.341439</td>\n      <td>0.906013</td>\n      <td>0.921701</td>\n      <td>0.261975</td>\n      <td>0.465083</td>\n      <td>8.481233</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.650609</td>\n      <td>0.375348</td>\n      <td>0.902567</td>\n      <td>0.555205</td>\n      <td>0.843531</td>\n      <td>0.748809</td>\n      <td>0.620126</td>\n      <td>0.541474</td>\n      <td>0.763846</td>\n      <td>8.364351</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.668980</td>\n      <td>0.239061</td>\n      <td>0.732948</td>\n      <td>0.679618</td>\n      <td>0.574844</td>\n      <td>0.346010</td>\n      <td>0.714610</td>\n      <td>0.540150</td>\n      <td>0.280682</td>\n      <td>8.049253</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.686964</td>\n      <td>0.420667</td>\n      <td>0.648182</td>\n      <td>0.684501</td>\n      <td>0.956692</td>\n      <td>1.000773</td>\n      <td>0.776742</td>\n      <td>0.625849</td>\n      <td>0.250823</td>\n      <td>7.972260</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"profile = ProfileReport(train_df, explorative=True)\nprofile = profile.load(\"/kaggle/input/edarep/EDA.pp\") \nprofile","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:14:21.674612Z","iopub.execute_input":"2021-09-01T00:14:21.67499Z","iopub.status.idle":"2021-09-01T00:14:45.303003Z","shell.execute_reply.started":"2021-09-01T00:14:21.674957Z","shell.execute_reply":"2021-09-01T00:14:45.301868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.corr().style.background_gradient(cmap='coolwarm').set_precision(2)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:15:21.390246Z","iopub.execute_input":"2021-09-01T00:15:21.390587Z","iopub.status.idle":"2021-09-01T00:15:21.650771Z","shell.execute_reply.started":"2021-09-01T00:15:21.390554Z","shell.execute_reply":"2021-09-01T00:15:21.649762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature engineering\nDid not find much benefit utilizing the engineered features below","metadata":{}},{"cell_type":"code","source":"# Count of alphabets (A ... O) in each row of categorical features\nobject_cols, cont_cols[1:-1]\n# cat_row_counts = train_df[object_cols].apply(pd.Series.value_counts, axis=1)[list(string.ascii_uppercase)[:15]].fillna(0)\n# cat_row_counts_test = test_df[object_cols].apply(pd.Series.value_counts, axis=1)[list(string.ascii_uppercase)[:15]].fillna(0)\nwith open('/kaggle/input/catrowcounts/cat_row_counts_full.pkl', 'rb') as pklfile:\n    cat_row_counts_train = pickle.load(pklfile)\nwith open('/kaggle/input/catrowcountstest/cat_row_counts_test.pkl', 'rb') as pklfile:\n    cat_row_counts_test = pickle.load(pklfile)\n\n# Calculate letter frequency & weightage\ndef calc_cat_freq_weight(df, df_eng, object_cols):\n    col_val_counts = [df[col].value_counts().to_dict() for col in object_cols]\n    dicts = [col_val_counts[0],\n            col_val_counts[1],\n            col_val_counts[2],\n            col_val_counts[3],\n            col_val_counts[4],\n            col_val_counts[5],\n            col_val_counts[6],\n            col_val_counts[7],\n            col_val_counts[8],\n            col_val_counts[9],\n            ]\n    c = Counter()\n    for d in dicts:\n        c.update(d)\n    total = sum(c.values())\n    weights = {key:val/total for key, val in c.items()}\n    [df_eng.replace(letter, weights[letter], inplace=True) for letter in (string.ascii_uppercase)[:15]]\n    [df_eng.rename(columns={col:f'{col}_'}, inplace=True) for col in object_cols]\n    return(df_eng)\n\ntrain_df_obj_eng = train_df[object_cols].copy()\ntrain_df_obj_eng = calc_cat_freq_weight(train_df[object_cols], train_df_obj_eng, object_cols)\ntrain_df_obj_eng = pd.concat([train_df_obj_eng, cat_row_counts_train], axis=1)\n\ntest_df_obj_eng = test_df[object_cols].copy()\ntest_df_obj_eng = calc_cat_freq_weight(test_df[object_cols], test_df_obj_eng, object_cols)\ntest_df_obj_eng = pd.concat([test_df_obj_eng, cat_row_counts_test], axis=1)\n\n# Construct dataframe with engineered features    \ndef calc_mul_mean_std(df, df_eng):\n    mult = pd.Series(np.array([1]*df.shape[0]))\n    for col in df.columns:\n        mult = mult * df[col]\n    df_eng['cont_cols_mult'] = mult\n    # Calculate mean,standard deviation for each row of continuous feature\n    mean = df.mean(axis=1)\n    std = df.std(axis=1)\n    # Construct dataframe with engineered features\n    df_eng['mean'] = mean\n    df_eng['std'] = std\n    return(df_eng)\n\ntrain_df_cont_eng = pd.DataFrame()\ntrain_df_cont_eng = calc_mul_mean_std(train_df[cont_cols[1:-1]], train_df_cont_eng)\ntrain_df_cont_eng = pd.concat([train_df[cont_cols[1:-1]], train_df_cont_eng], axis=1)\n\ntest_df_cont_eng = pd.DataFrame()\ntest_df_cont_eng = calc_mul_mean_std(test_df[cont_cols[1:-1]], test_df_cont_eng)\ntest_df_cont_eng = pd.concat([test_df[cont_cols[1:-1]], test_df_cont_eng], axis=1)\n\n# Consolidate into overall train & test engineered feature dataframes\n\ntrain_df_eng = pd.concat([train_df_obj_eng, train_df_cont_eng], axis=1)\ntest_df_eng = pd.concat([test_df_obj_eng, test_df_cont_eng], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:15:27.175428Z","iopub.execute_input":"2021-09-01T00:15:27.175828Z","iopub.status.idle":"2021-09-01T00:15:30.89663Z","shell.execute_reply.started":"2021-09-01T00:15:27.175786Z","shell.execute_reply":"2021-09-01T00:15:30.8954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create train, validate, test data","metadata":{}},{"cell_type":"code","source":"cont_cols = cont_cols[1:-1]\nobject_cols_ = ['cat0_', 'cat1_', 'cat2_', 'cat3_', 'cat4_', 'cat5_', 'cat6_', 'cat7_', 'cat8_', 'cat9_']\nalpha_cols = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O']\nstats_cols = ['cont_cols_mult', 'mean', 'std']\ndata_cols = ['object_cols', 'object_cols_', 'cont_cols', 'alpha_cols', 'stats_cols']\nprint (data_cols)\n\n# sub_cols = ['cat0_', 'cat1_', 'cat2_', 'cat3_', 'cat4_', 'cat5_', 'cat6_', 'cat7_',\n#        'cat8_', 'cat9_', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n#        'L', 'M', 'N', 'O', 'mean', 'std']\n# sub_cols = object_cols_ + stats_cols\nsub_cols = stats_cols\n\n# X = pd.concat([train_df.drop(columns=['id', 'target']), train_df_eng[sub_cols]], axis=1)\nX = train_df.drop(columns=['id', 'target'])  # Note:  Keeping the training set vanilla, since did not observe much benefit with the engineered features\nX_ = X.copy()\n# X_test = pd.concat([test_df.drop(columns=['id']), test_df_eng[sub_cols]], axis=1)\nX_test = test_df.drop(columns=['id'])\ny = train_df.target\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\nX_train = X_train.reset_index(drop=True)\nX_valid = X_valid.reset_index(drop=True)\n# print (X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape)\nprint (f'X.columns = {X.columns}')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:15:35.195499Z","iopub.execute_input":"2021-09-01T00:15:35.19595Z","iopub.status.idle":"2021-09-01T00:15:35.393626Z","shell.execute_reply.started":"2021-09-01T00:15:35.195916Z","shell.execute_reply":"2021-09-01T00:15:35.392718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode function","metadata":{}},{"cell_type":"code","source":"def encodeFeatures(encode=True):\n    if (encode):\n        scaler = StandardScaler()\n#         scaler = MinMaxScaler()\n        column_trans = make_column_transformer(\n            (OrdinalEncoder(), object_cols),\n#             (scaler, cont_cols[1:-1]),\n#             (scaler, X.columns),\n#             remainder = scaler\n            remainder='passthrough'\n        ) \n        return(column_trans)\n    else:\n        return (None)\n\nencode = True\ncolumn_trans = encodeFeatures(encode)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:09:20.907189Z","iopub.execute_input":"2021-09-01T00:09:20.907516Z","iopub.status.idle":"2021-09-01T00:09:20.915555Z","shell.execute_reply.started":"2021-09-01T00:09:20.907486Z","shell.execute_reply":"2021-09-01T00:09:20.914602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Principal component Analysis (PCA)\nDid not observe much benefit in reducing dimensionality","metadata":{}},{"cell_type":"code","source":"def pcaData (data, var_perc):\n  pca = PCA(n_components = var_perc)   # retain var_perc% of variance\n  principalComponents_data = pca.fit_transform(data)\n  return (principalComponents_data)\n\npca = False\nif (pca):\n    X_train_trans = column_trans.fit_transform(X_train)\n    # X_train_trans = scaler.fit_transform(X_train_trans)\n    pca_train = pcaData(X_train_trans, 0.95)\n\n    X_valid_trans = column_trans.fit_transform(X_valid)\n    # X_valid_trans = scaler.fit_transform(X_valid_trans)\n    pca_valid = pcaData(X_valid_trans, 0.95)\n\n    pca_train.shape, pca_valid.shape\nelse:\n    print ('Not performing PCA')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:15:45.654215Z","iopub.execute_input":"2021-09-01T00:15:45.654541Z","iopub.status.idle":"2021-09-01T00:15:45.660512Z","shell.execute_reply.started":"2021-09-01T00:15:45.654511Z","shell.execute_reply":"2021-09-01T00:15:45.659724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initialize models\nHyperparameters set mostly by trial and error","metadata":{}},{"cell_type":"code","source":"# Without GPU\n\nlr_model = LinearRegression()\n\nlgb_params1 = {\n    'objective': 'regression_l2',\n    'metric' : 'rmse',\n    'random_state': 0,\n    'learning_rate' : 0.05, # default = 0.1\n    'num_iterations' : 1200, # default = 100\n    'num_leaves' : 31, # default = 31\n    'max_depth' : 6, # default = -1\n    'min_child_samples' : 1000, # default = 20\n    'max_bin' : 255, # default = 255\n    'colsample_bytree' : 0.15, # default = 1.0\n    'reg_alpha' : 25, # default = 0\n    'reg_lambda' : 0, # default = 0\n    'min_split_gain' : 0, # default = 0|\n    'boosting_type' : 'gbdt'\n    }\nlgb_model1 = lgb.LGBMRegressor(**lgb_params1)\n\nxgb_params1 = {\n    'random_state': 0,\n    'learning_rate' : 0.08, # default = 0.3\n    'n_estimators' : 4700, # default = 100\n    'max_depth' : 3, # default = 6\n    'min_child_weight' : 7, # default = 1\n    'colsample_bytree' : 0.12, #default = 1\n    'reg_alpha' : 25, # default = 0\n    'reg_lambda' : 7, # default = 0/1\n    }\nxgb_model1 = XGBRegressor(**xgb_params1)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:20:02.534657Z","iopub.execute_input":"2021-09-01T00:20:02.535047Z","iopub.status.idle":"2021-09-01T00:20:02.543703Z","shell.execute_reply.started":"2021-09-01T00:20:02.535015Z","shell.execute_reply":"2021-09-01T00:20:02.542767Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# With GPU\n\ngpu_lgb_params1 = {\n    'objective': 'regression_l2',\n    'metric' : 'rmse',\n    'device' : \"gpu\",\n    'gpu_platform_id' : 0,\n    'gpu_device_id': 0,\n    'random_state': 0,\n    'learning_rate' : 0.05, # default = 0.1\n    'num_iterations' : 1200, # default = 100\n    'num_leaves' : 31, # default = 31\n    'max_depth' : 6, # default = -1\n    'min_child_samples' : 1000, # default = 20\n    'max_bin' : 255, # default = 255\n    'colsample_bytree' : 0.15, # default = 1.0\n    'reg_alpha' : 25, # default = 0\n    'reg_lambda' : 0, # default = 0\n    'min_split_gain' : 0, # default = 0\n    'boosting_type' : 'gbdt'\n    }\ngpu_lgb_model1 = lgb.LGBMRegressor(**gpu_lgb_params1)\n\ngpu_lgb_params2 = {\n    'objective': 'regression_l2',\n    'metric' : 'rmse',\n    'device' : \"gpu\",\n    'gpu_platform_id' : 0,\n    'gpu_device_id': 0,\n    'random_state': 0,\n    }\ngpu_lgb_model2 = lgb.LGBMRegressor(**gpu_lgb_params2)\n\ngpu_xgb_params1 = {\n    'tree_method':'gpu_hist',\n    'gpu_id': 0,\n    'predictor': 'gpu_predictor',\n    'random_state': 0,\n    'learning_rate' : 0.08, # default = 0.3\n    'n_estimators' : 4700, # default = 100\n    'max_depth' : 3, # default = 6\n    'min_child_weight' : 7, # default = 1\n    'colsample_bytree' : 0.12, #default = 1\n    'reg_alpha' : 25, # default = 0\n    'reg_lambda' : 7, # default = 0/1\n    }\ngpu_xgb_model1 = XGBRegressor(**gpu_xgb_params1)\n\ngpu_xgb_params2 = {\n    'tree_method':'gpu_hist',\n    'gpu_id': 0,\n    'predictor': 'gpu_predictor',\n    'random_state': 0\n    }\ngpu_xgb_model2 = XGBRegressor(**gpu_xgb_params2)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:19:59.910218Z","iopub.execute_input":"2021-09-01T00:19:59.910543Z","iopub.status.idle":"2021-09-01T00:19:59.922471Z","shell.execute_reply.started":"2021-09-01T00:19:59.910511Z","shell.execute_reply":"2021-09-01T00:19:59.921564Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Deep learning models\n\ndef plot_hist(history):\n  history_dict=history.history\n  loss_values = history_dict['loss']\n  val_loss_values=history_dict['val_loss']\n  plt.xlabel('Epochs')\n  plt.plot(loss_values, color='Blue', linestyle='dashed', marker='o', label='Training Loss')\n  plt.plot(val_loss_values,color='Red', label='Validation Loss')\n  plt.legend()\n  plt.show()\n\ndef dl_model1(X, y):\n    name = 'Model 1'\n\n    input_shape = X[0].shape\n    print (input_shape)\n\n    model = Sequential()\n    model.add(Dense(16, input_shape=input_shape, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(8, activation='relu'))\n    model.add(Dropout(0.2))\n#     model.add(Dense(16, activation='relu'))\n#     model.add(Dropout(0.2))\n    model.add(Dense(1,activation='linear'))\n    model.compile(Adam(lr=0.01), \n                loss='mse',\n                metrics=[RootMeanSquaredError()])\n    \n    # Runs model for 50 iterations and assigns this to 'history'\n    history = model.fit(X, y, epochs = 5, batch_size=64, validation_split = 0.2, verbose=1)\n\n    y_pred = model.predict(X)\n    print (f'RMSE for {name} = {mean_squared_error(y, y_pred, squared=False)}')\n\n    # Plot Training & Validation Loss\n    plot_hist(history)\n\n    return(model)\n\niters = 1\n\nfor iter in range(iters):\n    model_1 = dl_model1(column_trans.fit_transform(X), y)\n#     model_1 = dl_model1(np.array(X), y)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:19:06.982981Z","iopub.execute_input":"2021-09-01T00:19:06.983313Z","iopub.status.idle":"2021-09-01T00:19:50.804573Z","shell.execute_reply.started":"2021-09-01T00:19:06.983281Z","shell.execute_reply":"2021-09-01T00:19:50.803788Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"(24,)\nEpoch 1/5\n3750/3750 [==============================] - 8s 2ms/step - loss: 3.8403 - root_mean_squared_error: 1.8422 - val_loss: 0.5544 - val_root_mean_squared_error: 0.7446\nEpoch 2/5\n3750/3750 [==============================] - 7s 2ms/step - loss: 0.5603 - root_mean_squared_error: 0.7485 - val_loss: 0.5491 - val_root_mean_squared_error: 0.7410\nEpoch 3/5\n3750/3750 [==============================] - 8s 2ms/step - loss: 0.5500 - root_mean_squared_error: 0.7416 - val_loss: 0.5494 - val_root_mean_squared_error: 0.7412\nEpoch 4/5\n3750/3750 [==============================] - 7s 2ms/step - loss: 0.5544 - root_mean_squared_error: 0.7446 - val_loss: 0.5515 - val_root_mean_squared_error: 0.7427\nEpoch 5/5\n3750/3750 [==============================] - 7s 2ms/step - loss: 0.5511 - root_mean_squared_error: 0.7424 - val_loss: 0.5516 - val_root_mean_squared_error: 0.7427\nRMSE for Model 1 = 0.7438929468761204\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Set up pipeline & run cross validation\nEncode categorical features and run 5 fold cross validation\nUse Stacking Ensemble, with LightGBM & XGBoost as Base-Models and LinearRegression as the Meta-Model","metadata":{"execution":{"iopub.status.busy":"2021-08-19T01:24:19.599746Z","iopub.execute_input":"2021-08-19T01:24:19.600095Z","iopub.status.idle":"2021-08-19T01:24:19.60671Z","shell.execute_reply.started":"2021-08-19T01:24:19.600064Z","shell.execute_reply":"2021-08-19T01:24:19.605652Z"}}},{"cell_type":"code","source":"GPU = True\n# GPU = False\n\ndef pipeline(column_trans, model, model_label, X, y, encode, cv=5, pca=False):\n    if (encode):\n        if (pca):\n            pipe = make_pipeline(\n                column_trans,\n                PCA(n_components = 0.95),\n                model\n            )\n        else:\n            pipe = make_pipeline(\n                column_trans,\n                model\n            )\n    else:\n        pipe = make_pipeline(\n                model\n            )\n        \n    scores = -1 * cross_val_score(pipe, X, y, cv=cv, scoring='neg_root_mean_squared_error')\n    print (f'Mean score for {model_label} = {scores.mean()}')\n\nif (GPU):\n    estimators = [\n        ('gpu_lgb1', gpu_lgb_model1),\n        ('gpu_xgb1', gpu_xgb_model1)\n    ]\n    lgb_model = gpu_lgb_model1\n    xgb_model = gpu_xgb_model1\nelse:\n    estimators = [\n        ('lgb1', lgb_model1),\n        ('xgb1', xgb_model1)\n    ]\n    lgb_model = lgb_model1\n    xgb_model = lgb_model1\n\nstackreg = StackingRegressor(\n    estimators=estimators,\n    final_estimator=lr_model\n)\n\n\nfor model, model_label in zip([lgb_model, xgb_model, stackreg],['LightGBM','XGBoost','Stacking Regressor']):\n    pipeline(column_trans, model, model_label, X, y, encode=True, cv=5, pca=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:20:40.253046Z","iopub.execute_input":"2021-09-01T00:20:40.253402Z","iopub.status.idle":"2021-09-01T00:35:29.956862Z","shell.execute_reply.started":"2021-09-01T00:20:40.253371Z","shell.execute_reply":"2021-09-01T00:35:29.955694Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Mean score for LightGBM = 0.7185742402269343\nMean score for XGBoost = 0.7176847001404619\nMean score for Stacking Regressor = 0.7175107054086196\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Predict\nUse CPU for prediction - gives better results than GPU","metadata":{}},{"cell_type":"code","source":"estimators = [\n        ('lgb1', lgb_model1),\n        ('xgb1', xgb_model1)\n    ]\nlgb_model = lgb_model1\nxgb_model = lgb_model1\n\nstackreg = StackingRegressor(\n    estimators=estimators,\n    final_estimator=lr_model\n)\n\nstackreg","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:38:38.169149Z","iopub.execute_input":"2021-09-01T00:38:38.169481Z","iopub.status.idle":"2021-09-01T00:38:38.191068Z","shell.execute_reply.started":"2021-09-01T00:38:38.169451Z","shell.execute_reply":"2021-09-01T00:38:38.190288Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"StackingRegressor(estimators=[('lgb1',\n                               LGBMRegressor(colsample_bytree=0.15,\n                                             learning_rate=0.05, max_bin=255,\n                                             max_depth=6, metric='rmse',\n                                             min_child_samples=1000,\n                                             min_split_gain=0,\n                                             num_iterations=1200,\n                                             objective='regression_l2',\n                                             random_state=0, reg_alpha=25,\n                                             reg_lambda=0)),\n                              ('xgb1',\n                               XGBRegressor(base_score=None, booster=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=...\n                                            interaction_constraints=None,\n                                            learning_rate=0.08,\n                                            max_delta_step=None, max_depth=3,\n                                            min_child_weight=7, missing=nan,\n                                            monotone_constraints=None,\n                                            n_estimators=4700, n_jobs=None,\n                                            num_parallel_tree=None,\n                                            random_state=0, reg_alpha=25,\n                                            reg_lambda=7, scale_pos_weight=None,\n                                            subsample=None, tree_method=None,\n                                            validate_parameters=None,\n                                            verbosity=None))],\n                  final_estimator=LinearRegression())"},"metadata":{}}]},{"cell_type":"code","source":"def pred (column_trans, model, X, y, XValid, encode, pca=False):\n    if (encode):\n        if (pca):\n            pipe = make_pipeline(\n                column_trans,\n                PCA(n_components = 0.95),\n                model\n            )\n        else:\n            pipe = make_pipeline(\n                column_trans,\n                model\n            )\n    else:\n        pipe = make_pipeline(\n                model\n            )\n    pipe.fit(X, y)\n    preds = pipe.predict(XValid)\n    return (preds)\n\nmodels = [stackreg]\npredictions = [pred(column_trans, model, X, y, X_test, encode, pca=False) for model in models]","metadata":{"execution":{"iopub.status.busy":"2021-09-01T00:38:56.229969Z","iopub.execute_input":"2021-09-01T00:38:56.230305Z","iopub.status.idle":"2021-09-01T01:13:56.537312Z","shell.execute_reply.started":"2021-09-01T00:38:56.230274Z","shell.execute_reply":"2021-09-01T01:13:56.536434Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Prepare submission","metadata":{}},{"cell_type":"code","source":"# Take mean if using predictions from 2 models as the final output\n# mean_preds = np.concatenate([predictions[0].reshape(-1,1), predictions[1].reshape(-1,1)], axis=1).mean(axis=1)\n# sample_submission.target = mean_preds\n\n# If using predictions from a single model (including stacking) as a final output\nsample_submission.target = predictions[0]\nsample_submission.to_csv(\"submissionXX_stackreg.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T01:14:59.691623Z","iopub.execute_input":"2021-09-01T01:14:59.692010Z","iopub.status.idle":"2021-09-01T01:15:00.312392Z","shell.execute_reply.started":"2021-09-01T01:14:59.691978Z","shell.execute_reply":"2021-09-01T01:15:00.311513Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter tuning\nDidn't explore tuning using optuna in much detail.  Primarily used trial and error for hyperparameter settings as reflected in models above.","metadata":{}},{"cell_type":"code","source":"# Hyperparameter tuning\n\nimport optuna\n\ndef objective(trial):\n    learning_rate = trial.suggest_float(\"learning_rate\", 0.02, 0.1, log=True)\n    num_iterations = trial.suggest_int('num_iterations', 1000, 2000)\n#     num_leaves = trial.suggest_int('num_leaves', 2, 256),\n#     max_depth = trial.suggest_int('max_depth', 3, 10)\n#     min_child_samples = trial.suggest_int('min_child_samples', 5, 100)\n#     feature_fraction = trial.suggest_uniform('feature_fraction', 0.4, 1.0)\n#     colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 1.0)\n#     reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0)\n#     reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0)\n#     bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.4, 1.0)\n#     bagging_freq = trial.suggest_int('bagging_freq', 1, 7)\n    lgb_params = {\n        'objective': 'regression_l2',\n        'metric' : 'rmse',\n        'device' : \"gpu\",\n        'gpu_platform_id' : 0,\n        'gpu_device_id': 0,\n        'random_state': 0,\n        'learning_rate' : learning_rate, # default = 0.1\n        'num_iterations' : num_iterations, # default = 100\n        'num_leaves' : 31, # default = 31\n        'max_depth' : 6, # default = -1\n        'min_child_samples' : 1000, # default = 20\n        'max_bin' : 255, # default = 255\n        'colsample_bytree' : 0.15, # default = 1.0\n        'reg_alpha' : 25,\n        'reg_lambda' : 0,\n        'min_split_gain' : 0, # default = 0\n#         'feature_fraction' : feature_fraction,\n#         'bagging_fraction' : bagging_fraction,\n#         'bagging_freq' : bagging_freq,\n        'boosting_type' : 'gbdt'\n    }\n    lgb_model = lgb.LGBMRegressor(**lgb_params)\n    \n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n    xgb_params = {\n    'tree_method':'gpu_hist',\n    'gpu_id': 0,\n    'predictor': 'gpu_predictor',\n    'random_state': 0,\n    'n_estimators' : 10000, # default = 100\n    'max_depth' : 3, # default = 6\n    'min_child_weight' : 7, # default = 1\n    'learning_rate' : learning_rate,\n    'reg_lambda' : reg_lambda,\n    'reg_alpha' : reg_alpha,\n    'subsample' : subsample,\n    'colsample_bytree' : colsample_bytree,\n    }\n    xgb_model = XGBRegressor(**xgb_params)\n    \n    model = lgb_model\n#     model = xgb_model\n    \n    cv = 2\n    pca = False\n    \n    if (encode):\n        if (pca):\n            pipe = make_pipeline(\n                column_trans,\n                PCA(n_components = 0.95),\n                model\n            )\n        else:\n            pipe = make_pipeline(\n                column_trans,\n                model\n            )\n    else:\n        pipe = make_pipeline(\n                model\n            )\n        \n    scores = -1 * cross_val_score(pipe, X, y, cv=2, scoring='neg_root_mean_squared_error')\n    return (scores.mean())\n\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}